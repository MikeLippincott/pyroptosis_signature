{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine runs run parquet files into one"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import gc # garbage collection used to manage memory\n",
    "\n",
    "from pycytominer.cyto_utils import output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to parquet directory with annotated runs\n",
    "annotated_dir = pathlib.Path(\"./data/annotated_data\")\n",
    "\n",
    "# directory where the combined parquet file is saved to\n",
    "output_dir = pathlib.Path(\"./data/combined_data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# set path for combined run parquet file\n",
    "merged_runs_path = pathlib.Path(f\"{output_dir}/PBMC_sc.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths to each individual run file after annotation\n",
    "first_run_sc_path = pathlib.Path(f\"{annotated_dir}/batch_1_sc.parquet\")\n",
    "second_run_sc_path = pathlib.Path(f\"{annotated_dir}/batch_2_sc.parquet\")\n",
    "third_run_sc_path = pathlib.Path(f\"{annotated_dir}/batch_3_sc.parquet\")\n",
    "fourth_run_sc_path = pathlib.Path(f\"{annotated_dir}/batch_4_sc.parquet\")\n",
    "fifth_run_sc_path = pathlib.Path(f\"{annotated_dir}/batch_5_sc.parquet\")\n",
    "sixth_run_sc_path = pathlib.Path(f\"{annotated_dir}/batch_6_sc.parquet\")\n",
    "seventh_run_sc_path = pathlib.Path(f\"{annotated_dir}/batch_7_sc.parquet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the parquet files into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read parquet files into pandas dataframes\n",
    "print(\"Reading parquet files into pandas dataframes...\")\n",
    "first_run_sc = pd.read_parquet(first_run_sc_path)\n",
    "second_run_sc = pd.read_parquet(second_run_sc_path)\n",
    "third_run_sc = pd.read_parquet(third_run_sc_path)\n",
    "fourth_run_sc = pd.read_parquet(fourth_run_sc_path)\n",
    "fifth_run_sc = pd.read_parquet(fifth_run_sc_path)\n",
    "sixth_run_sc = pd.read_parquet(sixth_run_sc_path)\n",
    "seventh_run_sc = pd.read_parquet(seventh_run_sc_path)\n",
    "\n",
    "print(\"Merging runs into one dataframe...\")\n",
    "# concatenate dataframes and save as parquet file\n",
    "print(\"Concatenating dataframes 1 and 2...\")\n",
    "PBMC_run_sc = pd.concat(\n",
    "    [\n",
    "        first_run_sc,\n",
    "        second_run_sc\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "del first_run_sc, second_run_sc\n",
    "gc.collect()\n",
    "\n",
    "print(\"Concatenating dataframe 3\")\n",
    "\n",
    "PBMC_run_sc = pd.concat(\n",
    "    [\n",
    "    PBMC_run_sc,\n",
    "    third_run_sc,\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "del third_run_sc\n",
    "gc.collect()\n",
    "\n",
    "print(\"Concatenating dataframe 4\")\n",
    "PBMC_run_sc = pd.concat(\n",
    "    [\n",
    "    PBMC_run_sc,\n",
    "    fourth_run_sc,\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "del fourth_run_sc\n",
    "gc.collect()\n",
    "\n",
    "print(\"Concatenating dataframe 5\")\n",
    "PBMC_run_sc = pd.concat(\n",
    "    [\n",
    "    PBMC_run_sc,\n",
    "    fifth_run_sc,\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "del fifth_run_sc\n",
    "gc.collect()\n",
    "\n",
    "print(\"Concatenating dataframe 6\")\n",
    "PBMC_run_sc = pd.concat(\n",
    "    [\n",
    "    PBMC_run_sc,\n",
    "    sixth_run_sc,\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "del sixth_run_sc\n",
    "gc.collect()\n",
    "\n",
    "print(\"Concatenating dataframe 7\")\n",
    "PBMC_run_sc = pd.concat(\n",
    "    [\n",
    "    PBMC_run_sc,\n",
    "    seventh_run_sc,\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "del seventh_run_sc\n",
    "gc.collect()\n",
    "\n",
    "print(\"Saving merged runs to parquet file...\")\n",
    "\n",
    "output(\n",
    "    df=PBMC_run_sc,\n",
    "    output_filename=merged_runs_path,\n",
    "    output_type=\"parquet\",\n",
    ")\n",
    "print(f\"The runs have been merged into one file called {merged_runs_path.name}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if the merge function worked (should be approximately 600,000 rows)\n",
    "print(PBMC_run_sc.shape)\n",
    "PBMC_run_sc.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interstellar_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
