{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform feature selection on normalized data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import gc\n",
    "import pandas as pd\n",
    "\n",
    "from pycytominer import feature_select\n",
    "from pycytominer.cyto_utils import output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where normalized parquet file is located\n",
    "data_dir = pathlib.Path(\"./data/normalized_data\")\n",
    "\n",
    "# directory where the feature selected parquet file is saved to\n",
    "output_dir = pathlib.Path(\"./data/feature_selected_data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# define input path\n",
    "normalized_file_path = str(pathlib.Path(f\"{data_dir}/PBMC_sc_norm.parquet\"))\n",
    "\n",
    "# define ouput path\n",
    "feature_select_output_file = str(pathlib.Path(f\"{output_dir}/PBMC_sc_norm_fs.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process each run\n",
    "normalized_df = pd.read_parquet(normalized_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of operations for feature select function to use on input profile\n",
    "feature_select_ops = [\n",
    "    \"variance_threshold\",\n",
    "    \"blocklist\",\n",
    "    \"drop_na_columns\",\n",
    "]\n",
    "\n",
    "print(f\"Performing feature selection on normalized annotated merged single cells!\")\n",
    "\n",
    "# perform feature selection with the operations specified\n",
    "feature_select_df = feature_select(\n",
    "    normalized_df,\n",
    "    operation=feature_select_ops,\n",
    ")\n",
    "\n",
    "del normalized_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_select_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'well' is the column you want to stratify by\n",
    "feature_select_df = feature_select_df.groupby('Metadata_Well').apply(lambda x: x.sample(frac=0.01, random_state=0)).reset_index(drop=True)\n",
    "print(feature_select_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_select_ops = [\n",
    "    \"correlation_threshold\",\n",
    "]\n",
    "# perform feature selection with the operations specified\n",
    "feature_select_df = feature_select(\n",
    "    feature_select_df,\n",
    "    operation=feature_select_ops,\n",
    ")\n",
    "print(feature_select_df.shape)\n",
    "# get the column names of the feature selected dataframe\n",
    "feature_select_df_columns = feature_select_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the normalized dataframe\n",
    "normalized_df = pd.read_parquet(normalized_file_path)\n",
    "# filter the normalized dataframe to only include the columns that were selected\n",
    "feature_select_df = normalized_df.reindex(columns=feature_select_df_columns)\n",
    "print(feature_select_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save features selected df as parquet file\n",
    "output(\n",
    "    df=feature_select_df,\n",
    "    output_filename=feature_select_output_file,\n",
    "    output_type=\"parquet\"\n",
    ")\n",
    "print(f\"Features have been selected for PBMC cells and saved to {pathlib.Path(feature_select_output_file).name}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if the shape of the df has changed indicating feature selection occurred\n",
    "print(feature_select_df.shape)\n",
    "feature_select_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the metadata and profile data\n",
    "metadata_cols = feature_select_df.columns[feature_select_df.columns.str.contains(\"Metadata\")]\n",
    "profile_cols = feature_select_df.columns[~feature_select_df.columns.str.contains(\"Metadata\")]\n",
    "# get the number of features selected\n",
    "print(len(metadata_cols))\n",
    "print(len(profile_cols))\n",
    "print(len(normalized_df.columns)-len(metadata_cols))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interstellar_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
